{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c98da656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Kh_H2.1  Kh_CH4.1   void fraction [widom]   supercell volume [A^3]  \\\n",
      "0     0.046462  0.806263                0.774002              37137.01067   \n",
      "1     0.043839  0.285863                0.755095              88815.76359   \n",
      "2     0.042089  0.628554                0.527499              82897.38092   \n",
      "3     0.044269  0.450933                0.727666              33884.78447   \n",
      "4     0.043694  0.388438                0.714711              42906.37871   \n",
      "...        ...       ...                     ...                      ...   \n",
      "8693  0.045286  0.544446                0.674595             143246.12490   \n",
      "8694  0.046333  0.611321                0.678067              47431.63817   \n",
      "8695  0.040306  0.287475                0.610998              86927.30120   \n",
      "8696  0.040306  0.287475                0.611235              86927.30120   \n",
      "8697  0.044179  0.349743                0.762879              43368.64861   \n",
      "\n",
      "      dimensions   density [kg/m^3]   surface area [m^2/g]  \\\n",
      "0            3.0         451.212040                3049.10   \n",
      "1            3.0         341.629701                4360.50   \n",
      "2            3.0         699.650100                2218.02   \n",
      "3            3.0         486.654711                3113.75   \n",
      "4            3.0         523.110189                4317.22   \n",
      "...          ...                ...                    ...   \n",
      "8693         3.0         523.946165                3853.75   \n",
      "8694         3.0         531.689456                3499.73   \n",
      "8695         3.0         565.442427                3030.61   \n",
      "8696         3.0         565.442427                3030.61   \n",
      "8697         3.0         448.887734                4741.19   \n",
      "\n",
      "       deliverable capacity [v STP/v]   num carbon   num fluorine  ...  \\\n",
      "0                          146.497513        624.0            0.0  ...   \n",
      "1                          123.942455       1116.0            0.0  ...   \n",
      "2                           84.602055       2268.0            0.0  ...   \n",
      "3                          144.202061        608.0            0.0  ...   \n",
      "4                          155.099536        768.0            0.0  ...   \n",
      "...                               ...          ...            ...  ...   \n",
      "8693                       131.407773       3420.0            0.0  ...   \n",
      "8694                       135.519707        960.0            0.0  ...   \n",
      "8695                       127.919981       1920.0            0.0  ...   \n",
      "8696                       128.547696       1920.0            0.0  ...   \n",
      "8697                       162.067161        768.0            0.0  ...   \n",
      "\n",
      "       num silicon   vertices   edges   genus  \\\n",
      "0              0.0        1.0     4.0    25.0   \n",
      "1              0.0        1.0     2.0     7.0   \n",
      "2             54.0        1.0     3.0     7.0   \n",
      "3              0.0        1.0     2.0     5.0   \n",
      "4              0.0        1.0     4.0     9.0   \n",
      "...            ...        ...     ...     ...   \n",
      "8693           0.0        2.0     1.0     7.0   \n",
      "8694           0.0        1.0     3.0    25.0   \n",
      "8695           0.0        2.0     3.0     5.0   \n",
      "8696           0.0        2.0     3.0     5.0   \n",
      "8697           0.0        1.0     4.0     9.0   \n",
      "\n",
      "       largest included sphere diameter [A]  \\\n",
      "0                                  17.58356   \n",
      "1                                  22.33410   \n",
      "2                                   7.89938   \n",
      "3                                  15.88756   \n",
      "4                                  10.67615   \n",
      "...                                     ...   \n",
      "8693                                9.66709   \n",
      "8694                               19.03134   \n",
      "8695                               10.83553   \n",
      "8696                               10.83553   \n",
      "8697                               13.47683   \n",
      "\n",
      "       largest free sphere diameter [A]  \\\n",
      "0                              16.10518   \n",
      "1                              21.85891   \n",
      "2                               5.16156   \n",
      "3                              15.26200   \n",
      "4                               7.48489   \n",
      "...                                 ...   \n",
      "8693                            6.13332   \n",
      "8694                            5.95197   \n",
      "8695                            7.13014   \n",
      "8696                            7.13014   \n",
      "8697                            9.89170   \n",
      "\n",
      "       largest included sphere along free sphere path diameter [A]       0  \\\n",
      "0                                              17.51239                1.0   \n",
      "1                                              22.33410                2.0   \n",
      "2                                               7.89937                3.0   \n",
      "3                                              15.88036                4.0   \n",
      "4                                              10.27095                5.0   \n",
      "...                                                 ...                ...   \n",
      "8693                                            9.66693             8694.0   \n",
      "8694                                           19.03134             8695.0   \n",
      "8695                                           10.45866             8696.0   \n",
      "8696                                           10.45866             8697.0   \n",
      "8697                                           13.37131             8698.0   \n",
      "\n",
      "           0.1  TOP  \n",
      "0     0.000115  1.0  \n",
      "1     0.000230  1.0  \n",
      "2     0.000345  1.0  \n",
      "3     0.000460  1.0  \n",
      "4     0.000575  1.0  \n",
      "...        ...  ...  \n",
      "8693  0.999540  0.0  \n",
      "8694  0.999655  0.0  \n",
      "8695  0.999770  0.0  \n",
      "8696  0.999885  0.0  \n",
      "8697  1.000000  0.0  \n",
      "\n",
      "[8698 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data = pd.read_csv('./111.csv')\n",
    "selected_data = data.iloc[:8698, 22:]\n",
    "print(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adaa8da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.64616000e-02 8.06263000e-01 7.74002000e-01 ... 1.00000000e+00\n",
      "  1.14969000e-04 1.00000000e+00]\n",
      " [4.38391000e-02 2.85863000e-01 7.55095000e-01 ... 2.00000000e+00\n",
      "  2.29938000e-04 1.00000000e+00]\n",
      " [4.20891000e-02 6.28554000e-01 5.27499000e-01 ... 3.00000000e+00\n",
      "  3.44907000e-04 1.00000000e+00]\n",
      " ...\n",
      " [4.03058000e-02 2.87475000e-01 6.10998000e-01 ... 8.69600000e+03\n",
      "  9.99770062e-01 0.00000000e+00]\n",
      " [4.03058000e-02 2.87475000e-01 6.11235000e-01 ... 8.69700000e+03\n",
      "  9.99885031e-01 0.00000000e+00]\n",
      " [4.41792000e-02 3.49743000e-01 7.62879000e-01 ... 8.69800000e+03\n",
      "  1.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array = selected_data.to_numpy()\n",
    "print (numpy_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51cfc580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.38391000e-02 2.85863000e-01 7.55095000e-01 8.88157636e+04\n",
      " 3.00000000e+00 3.41629701e+02 4.36050000e+03 1.23942455e+02\n",
      " 1.11600000e+03 0.00000000e+00 8.28000000e+02 2.88000000e+02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
      " 2.00000000e+00 7.00000000e+00 2.23341000e+01 2.18589100e+01\n",
      " 2.23341000e+01 2.00000000e+00 2.29938000e-04 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "Mm = MinMaxScaler()\n",
    "X=selected_data.iloc[:, :].to_numpy()\n",
    "print(X[1])\n",
    "data = Mm.fit_transform(X)#归一化处理，为后面的监督学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e79532bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "[[ 0.0464616  0.806263   0.774002  ... 25.        17.58356   16.10518  ]\n",
      " [ 0.0438391  0.285863   0.755095  ...  7.        22.3341    21.85891  ]\n",
      " [ 0.0420891  0.628554   0.527499  ...  7.         7.89938    5.16156  ]\n",
      " ...\n",
      " [ 0.0403058  0.287475   0.610998  ...  5.        10.83553    7.13014  ]\n",
      " [ 0.0403058  0.287475   0.611235  ...  5.        10.83553    7.13014  ]\n",
      " [ 0.0441792  0.349743   0.762879  ...  9.        13.47683    9.8917   ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 提取特征数据和目标变量\n",
    "features = numpy_array[:, :-4]\n",
    "features1 = numpy_array[:, :-4]\n",
    "target = numpy_array[:, -1]\n",
    "print(target)\n",
    "print(features)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=999)\n",
    "#X_train1, X_test1, y_train1, y_test1 = train_test_split(features1, target, test_size=0.3, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d592cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 原始的训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=999)\n",
    "\n",
    "# 找到标签为1的索引\n",
    "index_of_ones = np.where(y_train == 1)[0]\n",
    "\n",
    "# 复制标签为1的数据多份\n",
    "num_copies_1 = 50  # 假设需要复制20份\n",
    "index_to_copy_1 = np.random.choice(index_of_ones, size=len(index_of_ones)*num_copies_1, replace=True)\n",
    "\n",
    "# 将标签为1的数据复制多份并添加到训练集中\n",
    "X_train_copies = np.concatenate([X_train, X_train[index_to_copy_1]])\n",
    "y_train_copies = np.concatenate([y_train, y_train[index_to_copy_1]])\n",
    "\n",
    "# 找到标签为2的索引\n",
    "index_of_twos = np.where(y_train == 2)[0]\n",
    "\n",
    "# 复制标签为2的数据多份\n",
    "num_copies_2 = 10  # 假设需要复制10份\n",
    "index_to_copy_2 = np.random.choice(index_of_twos, size=len(index_of_twos)*num_copies_2, replace=True)\n",
    "\n",
    "# 将标签为2的数据复制多份并添加到训练集中\n",
    "X_train_copies = np.concatenate([X_train_copies, X_train[index_to_copy_2]])\n",
    "y_train_copies = np.concatenate([y_train_copies, y_train[index_to_copy_2]])\n",
    "\n",
    "index_of_0s = np.where(y_train == 0)[0]\n",
    "\n",
    "# 复制标签为2的数据多份\n",
    "num_copies_0 = 2  # 假设需要复制10份\n",
    "index_to_copy_0 = np.random.choice(index_of_0s, size=len(index_of_0s)*num_copies_0, replace=True)\n",
    "\n",
    "# 将标签为2的数据复制多份并添加到训练集中\n",
    "X_train_copies = np.concatenate([X_train_copies, X_train[index_to_copy_0]])\n",
    "y_train_copies = np.concatenate([y_train_copies, y_train[index_to_copy_0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1223ff9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.32      0.46      1951\n",
      "         1.0       0.08      0.72      0.14       126\n",
      "         2.0       0.35      0.46      0.40       533\n",
      "\n",
      "    accuracy                           0.37      2610\n",
      "   macro avg       0.43      0.50      0.33      2610\n",
      "weighted avg       0.73      0.37      0.44      2610\n",
      "\n",
      "Confusion Matrix:\n",
      "[[618 901 432]\n",
      " [ 22  91  13]\n",
      " [ 71 218 244]]\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.95      0.90      1951\n",
      "         1.0       0.55      0.21      0.30       126\n",
      "         2.0       0.73      0.50      0.59       533\n",
      "\n",
      "    accuracy                           0.82      2610\n",
      "   macro avg       0.71      0.55      0.60      2610\n",
      "weighted avg       0.81      0.82      0.80      2610\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1858   11   82]\n",
      " [  84   26   16]\n",
      " [ 258   10  265]]\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.70      0.78      1951\n",
      "         1.0       0.14      0.45      0.21       126\n",
      "         2.0       0.53      0.65      0.59       533\n",
      "\n",
      "    accuracy                           0.68      2610\n",
      "   macro avg       0.52      0.60      0.53      2610\n",
      "weighted avg       0.78      0.68      0.72      2610\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1371  286  294]\n",
      " [  55   57   14]\n",
      " [ 119   65  349]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 建立SVM模型\n",
    "svm = SVC(kernel='linear', random_state=50,C= 1)\n",
    "svm.fit(X_train_copies, y_train_copies)\n",
    "predictions_svm = svm.predict(X_test)\n",
    "\n",
    "# 打印SVM分类报告和混淆矩阵\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, predictions_svm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_svm))\n",
    "\n",
    "# 建立随机森林模型\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=50)\n",
    "rf.fit(X_train_copies, y_train_copies)\n",
    "predictions_rf = rf.predict(X_test)\n",
    "\n",
    "# 打印随机森林分类报告和混淆矩阵\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, predictions_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_rf))\n",
    "\n",
    "# 建立梯度提升树模型\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=50)\n",
    "gbc.fit(X_train_copies, y_train_copies)\n",
    "predictions_gbc = gbc.predict(X_test)\n",
    "\n",
    "# 打印梯度提升树分类报告和混淆矩阵\n",
    "print(\"Gradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, predictions_gbc))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_gbc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b80162c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.84      0.84      1951\n",
      "         1.0       0.21      0.25      0.23       126\n",
      "         2.0       0.51      0.49      0.50       533\n",
      "\n",
      "    accuracy                           0.74      2610\n",
      "   macro avg       0.52      0.53      0.52      2610\n",
      "weighted avg       0.74      0.74      0.74      2610\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1635   87  229]\n",
      " [  74   32   20]\n",
      " [ 240   31  262]]\n",
      "k-Nearest Neighbors Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.76      0.79      1951\n",
      "         1.0       0.19      0.24      0.21       126\n",
      "         2.0       0.42      0.51      0.46       533\n",
      "\n",
      "    accuracy                           0.68      2610\n",
      "   macro avg       0.48      0.50      0.49      2610\n",
      "weighted avg       0.71      0.68      0.70      2610\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1487  107  357]\n",
      " [  73   30   23]\n",
      " [ 239   24  270]]\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.47      0.60      1951\n",
      "         1.0       0.11      0.56      0.18       126\n",
      "         2.0       0.30      0.51      0.37       533\n",
      "\n",
      "    accuracy                           0.48      2610\n",
      "   macro avg       0.42      0.51      0.39      2610\n",
      "weighted avg       0.70      0.48      0.54      2610\n",
      "\n",
      "Confusion Matrix:\n",
      "[[913 426 612]\n",
      " [ 29  70  27]\n",
      " [127 136 270]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiuyong/.conda/envs/LiIonMl/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 建立决策树模型\n",
    "dt = DecisionTreeClassifier(random_state=50)\n",
    "dt.fit(X_train_copies, y_train_copies)\n",
    "predictions_dt = dt.predict(X_test)\n",
    "\n",
    "# 打印决策树分类报告和混淆矩阵\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, predictions_dt))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_dt))\n",
    "\n",
    "# 建立k-Nearest Neighbors模型\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_copies, y_train_copies)\n",
    "predictions_knn = knn.predict(X_test)\n",
    "\n",
    "# 打印k-Nearest Neighbors分类报告和混淆矩阵\n",
    "print(\"k-Nearest Neighbors Classification Report:\")\n",
    "print(classification_report(y_test, predictions_knn))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_knn))\n",
    "\n",
    "# 建立Logistic Regression模型\n",
    "lr = LogisticRegression(max_iter=1000, random_state=50)\n",
    "lr.fit(X_train_copies, y_train_copies)\n",
    "predictions_lr = lr.predict(X_test)\n",
    "\n",
    "# 打印Logistic Regression分类报告和混淆矩阵\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, predictions_lr))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4b4ab926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵:\n",
      "[[1903    7   41]\n",
      " [  89   23   14]\n",
      " [ 312    7  214]]\n",
      "加权平均预测准确率: 0.8199233716475096\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 假设predictions_rf、predictions_dt、predictions_knn是随机森林、决策树和k-Nearest Neighbors的预测结果\n",
    "# 分别对应模型的类别概率\n",
    "probs_rf = rf.predict_proba(X_test)\n",
    "probs_dt = dt.predict_proba(X_test)\n",
    "probs_knn = knn.predict_proba(X_test)\n",
    "\n",
    "# 对预测类型1的加权平均\n",
    "weighted_avg_probs = 0.4 * probs_rf[:, 0] + 0.3 * probs_dt[:, 0] + 0.3 * probs_knn[:, 0]\n",
    "#print(probs_rf[:, 0])\n",
    "# 设置阈值，当加权平均概率超过阈值时，认定为类型1\n",
    "threshold = 0.4\n",
    "\n",
    "# 根据阈值判断最终的预测类型\n",
    "final_predictions = np.where(weighted_avg_probs > threshold,0,predictions_rf)\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, final_predictions)\n",
    "\n",
    "print(\"混淆矩阵:\")\n",
    "print(conf_matrix)\n",
    "print(\"加权平均预测准确率:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f003bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 原始的训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=999)\n",
    "\n",
    "# 找到标签为1的索引\n",
    "index_of_ones = np.where(y_train == 1)[0]\n",
    "\n",
    "# 复制标签为1的数据多份\n",
    "num_copies_1 = 30  # 假设需要复制20份\n",
    "index_to_copy_1 = np.random.choice(index_of_ones, size=len(index_of_ones)*num_copies_1, replace=True)\n",
    "\n",
    "# 将标签为1的数据复制多份并添加到训练集中\n",
    "X_train_copies = np.concatenate([X_train, X_train[index_to_copy_1]])\n",
    "y_train_copies = np.concatenate([y_train, y_train[index_to_copy_1]])\n",
    "\n",
    "# 找到标签为2的索引\n",
    "index_of_twos = np.where(y_train == 2)[0]\n",
    "\n",
    "# 复制标签为2的数据多份\n",
    "num_copies_2 = 10  # 假设需要复制10份\n",
    "index_to_copy_2 = np.random.choice(index_of_twos, size=len(index_of_twos)*num_copies_2, replace=True)\n",
    "\n",
    "# 将标签为2的数据复制多份并添加到训练集中\n",
    "X_train_copies = np.concatenate([X_train_copies, X_train[index_to_copy_2]])\n",
    "y_train_copies = np.concatenate([y_train_copies, y_train[index_to_copy_2]])\n",
    "\n",
    "index_of_0s = np.where(y_train == 0)[0]\n",
    "\n",
    "# 复制标签为2的数据多份\n",
    "num_copies_0 = 2  # 假设需要复制10份\n",
    "index_to_copy_0 = np.random.choice(index_of_0s, size=len(index_of_0s)*num_copies_0, replace=True)\n",
    "\n",
    "# 将标签为2的数据复制多份并添加到训练集中\n",
    "X_train_copies = np.concatenate([X_train_copies, X_train[index_to_copy_0]])\n",
    "y_train_copies = np.concatenate([y_train_copies, y_train[index_to_copy_0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a00f799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.52      0.65      1951\n",
      "         1.0       0.11      0.48      0.17       126\n",
      "         2.0       0.37      0.60      0.46       533\n",
      "\n",
      "    accuracy                           0.54      2610\n",
      "   macro avg       0.45      0.53      0.43      2610\n",
      "weighted avg       0.72      0.54      0.59      2610\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1024  413  514]\n",
      " [  42   60   24]\n",
      " [ 124   90  319]]\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.95      0.90      1951\n",
      "         1.0       0.59      0.25      0.36       126\n",
      "         2.0       0.74      0.50      0.60       533\n",
      "\n",
      "    accuracy                           0.83      2610\n",
      "   macro avg       0.73      0.57      0.62      2610\n",
      "weighted avg       0.81      0.83      0.81      2610\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1858   12   81]\n",
      " [  79   32   15]\n",
      " [ 256   10  267]]\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.76      0.82      1951\n",
      "         1.0       0.18      0.37      0.24       126\n",
      "         2.0       0.53      0.66      0.59       533\n",
      "\n",
      "    accuracy                           0.72      2610\n",
      "   macro avg       0.53      0.60      0.55      2610\n",
      "weighted avg       0.78      0.72      0.75      2610\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1492  162  297]\n",
      " [  62   46   18]\n",
      " [ 130   50  353]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 建立SVM模型\n",
    "svm = SVC(kernel='linear', random_state=50,C= 1)\n",
    "svm.fit(X_train_copies, y_train_copies)\n",
    "predictions_svm = svm.predict(X_test)\n",
    "\n",
    "# 打印SVM分类报告和混淆矩阵\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, predictions_svm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_svm))\n",
    "\n",
    "# 建立随机森林模型\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=50)\n",
    "rf.fit(X_train_copies, y_train_copies)\n",
    "predictions_rf = rf.predict(X_test)\n",
    "\n",
    "# 打印随机森林分类报告和混淆矩阵\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, predictions_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_rf))\n",
    "\n",
    "# 建立梯度提升树模型\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=50)\n",
    "gbc.fit(X_train_copies, y_train_copies)\n",
    "predictions_gbc = gbc.predict(X_test)\n",
    "\n",
    "# 打印梯度提升树分类报告和混淆矩阵\n",
    "print(\"Gradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, predictions_gbc))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e911f704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.85      0.85      1951\n",
      "         1.0       0.27      0.31      0.29       126\n",
      "         2.0       0.55      0.50      0.52       533\n",
      "\n",
      "    accuracy                           0.76      2610\n",
      "   macro avg       0.55      0.55      0.55      2610\n",
      "weighted avg       0.75      0.76      0.75      2610\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1665   84  202]\n",
      " [  69   39   18]\n",
      " [ 245   21  267]]\n",
      "k-Nearest Neighbors Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.77      0.80      1951\n",
      "         1.0       0.20      0.25      0.23       126\n",
      "         2.0       0.42      0.50      0.46       533\n",
      "\n",
      "    accuracy                           0.69      2610\n",
      "   macro avg       0.48      0.51      0.49      2610\n",
      "weighted avg       0.72      0.69      0.70      2610\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1502  103  346]\n",
      " [  69   32   25]\n",
      " [ 241   23  269]]\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.56      0.67      1951\n",
      "         1.0       0.17      0.42      0.24       126\n",
      "         2.0       0.29      0.56      0.39       533\n",
      "\n",
      "    accuracy                           0.55      2610\n",
      "   macro avg       0.44      0.51      0.43      2610\n",
      "weighted avg       0.70      0.55      0.59      2610\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1088  179  684]\n",
      " [  40   53   33]\n",
      " [ 158   76  299]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiuyong/.conda/envs/LiIonMl/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 建立决策树模型\n",
    "dt = DecisionTreeClassifier(random_state=50)\n",
    "dt.fit(X_train_copies, y_train_copies)\n",
    "predictions_dt = dt.predict(X_test)\n",
    "\n",
    "# 打印决策树分类报告和混淆矩阵\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, predictions_dt))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_dt))\n",
    "\n",
    "# 建立k-Nearest Neighbors模型\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_copies, y_train_copies)\n",
    "predictions_knn = knn.predict(X_test)\n",
    "\n",
    "# 打印k-Nearest Neighbors分类报告和混淆矩阵\n",
    "print(\"k-Nearest Neighbors Classification Report:\")\n",
    "print(classification_report(y_test, predictions_knn))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_knn))\n",
    "\n",
    "# 建立Logistic Regression模型\n",
    "lr = LogisticRegression(max_iter=1000, random_state=50)\n",
    "lr.fit(X_train_copies, y_train_copies)\n",
    "predictions_lr = lr.predict(X_test)\n",
    "\n",
    "# 打印Logistic Regression分类报告和混淆矩阵\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, predictions_lr))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a53077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵:\n",
      "[[1905    8   38]\n",
      " [  85   31   10]\n",
      " [ 319    9  205]]\n",
      "加权平均预测准确率: 0.8203065134099616\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 假设predictions_rf、predictions_dt、predictions_knn是随机森林、决策树和k-Nearest Neighbors的预测结果\n",
    "# 分别对应模型的类别概率\n",
    "probs_rf = rf.predict_proba(X_test)\n",
    "probs_dt = dt.predict_proba(X_test)\n",
    "probs_knn = knn.predict_proba(X_test)\n",
    "\n",
    "# 对预测类型1的加权平均\n",
    "weighted_avg_probs = 0.4 * probs_rf[:, 0] + 0.3 * probs_dt[:, 0] + 0.3 * probs_knn[:, 0]\n",
    "#print(probs_rf[:, 0])\n",
    "# 设置阈值，当加权平均概率超过阈值时，认定为类型1\n",
    "threshold = 0.4\n",
    "\n",
    "# 根据阈值判断最终的预测类型\n",
    "final_predictions = np.where(weighted_avg_probs > threshold,0,predictions_rf)\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, final_predictions)\n",
    "\n",
    "print(\"混淆矩阵:\")\n",
    "print(conf_matrix)\n",
    "print(\"加权平均预测准确率:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27614ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵:\n",
      "[[1903    7   41]\n",
      " [  85   31   10]\n",
      " [ 305    8  220]]\n",
      "加权平均预测准确率: 0.825287356321839\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 假设predictions_rf、predictions_dt、predictions_knn是随机森林、决策树和k-Nearest Neighbors的预测结果\n",
    "# 分别对应模型的类别概率\n",
    "probs_rf = rf.predict_proba(X_test)\n",
    "probs_dt = dt.predict_proba(X_test)\n",
    "probs_knn = knn.predict_proba(X_test)\n",
    "\n",
    "# 对预测类型1的加权平均\n",
    "weighted_avg_probs = 0.5 * probs_rf[:, 0] + 0.3 * probs_dt[:, 0] + 0.2 * probs_knn[:, 0]\n",
    "#print(probs_rf[:, 0])\n",
    "# 设置阈值，当加权平均概率超过阈值时，认定为类型1\n",
    "threshold = 0.4\n",
    "\n",
    "# 根据阈值判断最终的预测类型\n",
    "final_predictions = np.where(weighted_avg_probs > threshold,0,predictions_rf)\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, final_predictions)\n",
    "\n",
    "print(\"混淆矩阵:\")\n",
    "print(conf_matrix)\n",
    "print(\"加权平均预测准确率:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5cb274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LiIonMl",
   "language": "python",
   "name": "qiuyong"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
