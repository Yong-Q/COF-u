{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c98da656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        aIM   void fraction [widom]   supercell volume [A^3]  \\\n",
      "0     31.40                0.105459              38509.22698   \n",
      "1     10.40                0.131969              64604.38487   \n",
      "2     21.60                0.707530              52695.26737   \n",
      "3     12.80                0.623734              41430.89922   \n",
      "4     47.10                0.098176              37817.08628   \n",
      "...     ...                     ...                      ...   \n",
      "8995  61.10                0.404401              22412.96386   \n",
      "8996   5.68                0.836335              83255.73528   \n",
      "8997  18.40                0.571203              42780.90328   \n",
      "8998   7.16                0.733253              63185.68060   \n",
      "8999  18.80                0.632062              41641.98342   \n",
      "\n",
      "       density [kg/m^3]   surface area [m^2/g]  \\\n",
      "0            944.824172               215.4120   \n",
      "1            787.966755               537.6830   \n",
      "2            474.663293              3296.0600   \n",
      "3            637.096493              3058.4000   \n",
      "4            965.229974                80.1189   \n",
      "...                 ...                    ...   \n",
      "8995         904.158291               781.7190   \n",
      "8996         341.182782              6560.0600   \n",
      "8997         611.857621              2320.9400   \n",
      "8998         437.860112              5231.6000   \n",
      "8999         645.727237              2928.3400   \n",
      "\n",
      "       deliverable capacity [v STP/v]  dimensions.1   num carbon  \\\n",
      "0                           11.584131           3.0       1296.0   \n",
      "1                           16.827701           3.0        864.0   \n",
      "2                          141.153986           2.0        792.0   \n",
      "3                          104.914284           3.0       1080.0   \n",
      "4                            4.479950           3.0       1296.0   \n",
      "...                               ...           ...          ...   \n",
      "8995                        41.733578           3.0        768.0   \n",
      "8996                       169.039010           3.0       1080.0   \n",
      "8997                       104.691766           3.0       1248.0   \n",
      "8998                       161.896701           3.0       1312.0   \n",
      "8999                       109.015898           3.0        960.0   \n",
      "\n",
      "       num fluorine   num hydrogen  ...   num silicon   vertices   edges  \\\n",
      "0               0.0         1008.0  ...           0.0        1.0     1.0   \n",
      "1               0.0          720.0  ...           0.0        1.0     1.0   \n",
      "2               0.0          504.0  ...           0.0        2.0     2.0   \n",
      "3               0.0          648.0  ...          27.0        1.0     2.0   \n",
      "4               0.0          936.0  ...           0.0        1.0     1.0   \n",
      "...             ...            ...  ...           ...        ...     ...   \n",
      "8995            0.0          288.0  ...           0.0        2.0     2.0   \n",
      "8996            0.0          672.0  ...           0.0        1.0     1.0   \n",
      "8997            0.0          768.0  ...           0.0        1.0     3.0   \n",
      "8998            0.0          896.0  ...           0.0        1.0     2.0   \n",
      "8999            0.0          624.0  ...           0.0        1.0     2.0   \n",
      "\n",
      "       genus   largest included sphere diameter [A]  \\\n",
      "0        4.0                                4.35262   \n",
      "1        4.0                                6.09599   \n",
      "2        0.0                               16.14700   \n",
      "3        4.0                                7.58826   \n",
      "4        4.0                                4.15814   \n",
      "...      ...                                    ...   \n",
      "8995    11.0                                6.74433   \n",
      "8996     3.0                               14.04661   \n",
      "8997     9.0                               14.36059   \n",
      "8998     9.0                               12.97633   \n",
      "8999     5.0                                8.73583   \n",
      "\n",
      "       largest free sphere diameter [A]  \\\n",
      "0                               4.05572   \n",
      "1                               5.12149   \n",
      "2                              14.67949   \n",
      "3                               6.48919   \n",
      "4                               3.68395   \n",
      "...                                 ...   \n",
      "8995                            3.70913   \n",
      "8996                           10.99640   \n",
      "8997                           11.42470   \n",
      "8998                            7.75315   \n",
      "8999                            6.33516   \n",
      "\n",
      "       largest included sphere along free sphere path diameter [A]       0  \\\n",
      "0                                               4.35262                1.0   \n",
      "1                                               6.09599                2.0   \n",
      "2                                              16.14699                3.0   \n",
      "3                                               7.57964                4.0   \n",
      "4                                               3.96723                5.0   \n",
      "...                                                 ...                ...   \n",
      "8995                                            6.73837             8996.0   \n",
      "8996                                           14.04661             8997.0   \n",
      "8997                                           14.22528             8998.0   \n",
      "8998                                           12.89060             8999.0   \n",
      "8999                                            8.73583             9000.0   \n",
      "\n",
      "      Unnamed: 43  Unnamed: 44  \n",
      "0        0.000100          1.0  \n",
      "1        0.000201          1.0  \n",
      "2        0.000301          1.0  \n",
      "3        0.000401          1.0  \n",
      "4        0.000502          1.0  \n",
      "...           ...          ...  \n",
      "8995     0.902307          0.0  \n",
      "8996     0.902407          0.0  \n",
      "8997     0.902508          0.0  \n",
      "8998     0.902608          0.0  \n",
      "8999     0.902708          0.0  \n",
      "\n",
      "[9000 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data = pd.read_csv('./K.csv')\n",
    "selected_data = data.iloc[:9000, 22:]\n",
    "print(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adaa8da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.14000000e+01 1.05459000e-01 3.85092270e+04 ... 1.00000000e+00\n",
      "  1.00301000e-04 1.00000000e+00]\n",
      " [1.04000000e+01 1.31969000e-01 6.46043849e+04 ... 2.00000000e+00\n",
      "  2.00602000e-04 1.00000000e+00]\n",
      " [2.16000000e+01 7.07530000e-01 5.26952674e+04 ... 3.00000000e+00\n",
      "  3.00903000e-04 1.00000000e+00]\n",
      " ...\n",
      " [1.84000000e+01 5.71203000e-01 4.27809033e+04 ... 8.99800000e+03\n",
      "  9.02507523e-01 0.00000000e+00]\n",
      " [7.16000000e+00 7.33253000e-01 6.31856806e+04 ... 8.99900000e+03\n",
      "  9.02607823e-01 0.00000000e+00]\n",
      " [1.88000000e+01 6.32062000e-01 4.16419834e+04 ... 9.00000000e+03\n",
      "  9.02708124e-01 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array = selected_data.to_numpy()\n",
    "print (numpy_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51cfc580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.04000000e+01 1.31969000e-01 6.46043849e+04 7.87966755e+02\n",
      " 5.37683000e+02 1.68277013e+01 3.00000000e+00 8.64000000e+02\n",
      " 0.00000000e+00 7.20000000e+02 1.92000000e+02 9.60000000e+01\n",
      " 0.00000000e+00 0.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 4.00000000e+00 6.09599000e+00 5.12149000e+00 6.09599000e+00\n",
      " 2.00000000e+00 2.00602000e-04 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "Mm = MinMaxScaler()\n",
    "X=selected_data.iloc[:, :].to_numpy()\n",
    "print(X[1])\n",
    "data = Mm.fit_transform(X)#归一化处理，为后面的监督学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e79532bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "[[3.14000000e+01 1.05459000e-01 3.85092270e+04 ... 4.00000000e+00\n",
      "  4.35262000e+00 4.05572000e+00]\n",
      " [1.04000000e+01 1.31969000e-01 6.46043849e+04 ... 4.00000000e+00\n",
      "  6.09599000e+00 5.12149000e+00]\n",
      " [2.16000000e+01 7.07530000e-01 5.26952674e+04 ... 0.00000000e+00\n",
      "  1.61470000e+01 1.46794900e+01]\n",
      " ...\n",
      " [1.84000000e+01 5.71203000e-01 4.27809033e+04 ... 9.00000000e+00\n",
      "  1.43605900e+01 1.14247000e+01]\n",
      " [7.16000000e+00 7.33253000e-01 6.31856806e+04 ... 9.00000000e+00\n",
      "  1.29763300e+01 7.75315000e+00]\n",
      " [1.88000000e+01 6.32062000e-01 4.16419834e+04 ... 5.00000000e+00\n",
      "  8.73583000e+00 6.33516000e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = numpy_array[:, :-4]\n",
    "features1 = numpy_array[:, :-4]\n",
    "target = numpy_array[:, -1]\n",
    "print(target)\n",
    "print(features)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=999)\n",
    "#X_train1, X_test1, y_train1, y_test1 = train_test_split(features1, target, test_size=0.3, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d592cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=999)\n",
    "\n",
    "\n",
    "index_of_ones = np.where(y_train == 1)[0]\n",
    "\n",
    "\n",
    "num_copies_1 = 50  \n",
    "index_to_copy_1 = np.random.choice(index_of_ones, size=len(index_of_ones)*num_copies_1, replace=True)\n",
    "\n",
    "\n",
    "X_train_copies = np.concatenate([X_train, X_train[index_to_copy_1]])\n",
    "y_train_copies = np.concatenate([y_train, y_train[index_to_copy_1]])\n",
    "\n",
    "\n",
    "index_of_twos = np.where(y_train == 2)[0]\n",
    "\n",
    "\n",
    "num_copies_2 = 10  \n",
    "index_to_copy_2 = np.random.choice(index_of_twos, size=len(index_of_twos)*num_copies_2, replace=True)\n",
    "\n",
    "\n",
    "X_train_copies = np.concatenate([X_train_copies, X_train[index_to_copy_2]])\n",
    "y_train_copies = np.concatenate([y_train_copies, y_train[index_to_copy_2]])\n",
    "\n",
    "index_of_0s = np.where(y_train == 0)[0]\n",
    "\n",
    "\n",
    "num_copies_0 = 2  \n",
    "index_to_copy_0 = np.random.choice(index_of_0s, size=len(index_of_0s)*num_copies_0, replace=True)\n",
    "\n",
    "\n",
    "X_train_copies = np.concatenate([X_train_copies, X_train[index_to_copy_0]])\n",
    "y_train_copies = np.concatenate([y_train_copies, y_train[index_to_copy_0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1223ff9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.56      0.68      1941\n",
      "         1.0       0.17      0.74      0.28       144\n",
      "         2.0       0.41      0.59      0.49       615\n",
      "\n",
      "    accuracy                           0.57      2700\n",
      "   macro avg       0.49      0.63      0.48      2700\n",
      "weighted avg       0.74      0.57      0.62      2700\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1078  369  494]\n",
      " [  17  106   21]\n",
      " [ 121  131  363]]\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.94      0.89      1941\n",
      "         1.0       0.69      0.49      0.57       144\n",
      "         2.0       0.73      0.53      0.62       615\n",
      "\n",
      "    accuracy                           0.83      2700\n",
      "   macro avg       0.76      0.65      0.69      2700\n",
      "weighted avg       0.82      0.83      0.81      2700\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1829   10  102]\n",
      " [  53   70   21]\n",
      " [ 265   21  329]]\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.79      0.84      1941\n",
      "         1.0       0.34      0.69      0.46       144\n",
      "         2.0       0.56      0.64      0.60       615\n",
      "\n",
      "    accuracy                           0.75      2700\n",
      "   macro avg       0.60      0.71      0.63      2700\n",
      "weighted avg       0.79      0.75      0.77      2700\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1533  123  285]\n",
      " [  14  100   30]\n",
      " [ 150   71  394]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', random_state=50,C= 1)\n",
    "svm.fit(X_train_copies, y_train_copies)\n",
    "predictions_svm = svm.predict(X_test)\n",
    "\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, predictions_svm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_svm))\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=50)\n",
    "rf.fit(X_train_copies, y_train_copies)\n",
    "predictions_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, predictions_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_rf))\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=50)\n",
    "gbc.fit(X_train_copies, y_train_copies)\n",
    "predictions_gbc = gbc.predict(X_test)\n",
    "\n",
    "print(\"Gradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, predictions_gbc))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_gbc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b80162c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.85      0.85      1941\n",
      "         1.0       0.43      0.42      0.42       144\n",
      "         2.0       0.54      0.53      0.54       615\n",
      "\n",
      "    accuracy                           0.76      2700\n",
      "   macro avg       0.61      0.60      0.60      2700\n",
      "weighted avg       0.75      0.76      0.76      2700\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1658   39  244]\n",
      " [  54   60   30]\n",
      " [ 248   41  326]]\n",
      "k-Nearest Neighbors Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.78      0.80      1941\n",
      "         1.0       0.29      0.32      0.30       144\n",
      "         2.0       0.44      0.53      0.48       615\n",
      "\n",
      "    accuracy                           0.70      2700\n",
      "   macro avg       0.52      0.54      0.53      2700\n",
      "weighted avg       0.72      0.70      0.70      2700\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1505   68  368]\n",
      " [  56   46   42]\n",
      " [ 245   44  326]]\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.42      0.56      1941\n",
      "         1.0       0.16      0.67      0.26       144\n",
      "         2.0       0.30      0.57      0.39       615\n",
      "\n",
      "    accuracy                           0.46      2700\n",
      "   macro avg       0.44      0.55      0.40      2700\n",
      "weighted avg       0.69      0.46      0.51      2700\n",
      "\n",
      "Confusion Matrix:\n",
      "[[806 370 765]\n",
      " [ 13  96  35]\n",
      " [126 141 348]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiuyong/.conda/envs/LiIonMl/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=50)\n",
    "dt.fit(X_train_copies, y_train_copies)\n",
    "predictions_dt = dt.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, predictions_dt))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_dt))\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_copies, y_train_copies)\n",
    "predictions_knn = knn.predict(X_test)\n",
    "\n",
    "print(\"k-Nearest Neighbors Classification Report:\")\n",
    "print(classification_report(y_test, predictions_knn))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_knn))\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000, random_state=50)\n",
    "lr.fit(X_train_copies, y_train_copies)\n",
    "predictions_lr = lr.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, predictions_lr))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b4ab926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵:\n",
      "[[1881    9   51]\n",
      " [  69   60   15]\n",
      " [ 340   14  261]]\n",
      "加权平均预测准确率: 0.8155555555555556\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "probs_rf = rf.predict_proba(X_test)\n",
    "probs_dt = dt.predict_proba(X_test)\n",
    "probs_knn = knn.predict_proba(X_test)\n",
    "\n",
    "\n",
    "weighted_avg_probs = 0.4 * probs_rf[:, 0] + 0.3 * probs_dt[:, 0] + 0.3 * probs_knn[:, 0]\n",
    "\n",
    "threshold = 0.4\n",
    "\n",
    "final_predictions = np.where(weighted_avg_probs > threshold,0,predictions_rf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, final_predictions)\n",
    "\n",
    "print(\"混淆矩阵:\")\n",
    "print(conf_matrix)\n",
    "print(\"加权平均预测准确率:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f003bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=999)\n",
    "\n",
    "index_of_ones = np.where(y_train == 1)[0]\n",
    "\n",
    "num_copies_1 = 30  \n",
    "index_to_copy_1 = np.random.choice(index_of_ones, size=len(index_of_ones)*num_copies_1, replace=True)\n",
    "\n",
    "X_train_copies = np.concatenate([X_train, X_train[index_to_copy_1]])\n",
    "y_train_copies = np.concatenate([y_train, y_train[index_to_copy_1]])\n",
    "\n",
    "index_of_twos = np.where(y_train == 2)[0]\n",
    "\n",
    "num_copies_2 = 10  \n",
    "index_to_copy_2 = np.random.choice(index_of_twos, size=len(index_of_twos)*num_copies_2, replace=True)\n",
    "\n",
    "X_train_copies = np.concatenate([X_train_copies, X_train[index_to_copy_2]])\n",
    "y_train_copies = np.concatenate([y_train_copies, y_train[index_to_copy_2]])\n",
    "\n",
    "index_of_0s = np.where(y_train == 0)[0]\n",
    "\n",
    "num_copies_0 = 2  \n",
    "index_to_copy_0 = np.random.choice(index_of_0s, size=len(index_of_0s)*num_copies_0, replace=True)\n",
    "\n",
    "X_train_copies = np.concatenate([X_train_copies, X_train[index_to_copy_0]])\n",
    "y_train_copies = np.concatenate([y_train_copies, y_train[index_to_copy_0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a00f799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.56      0.69      1941\n",
      "         1.0       0.22      0.61      0.33       144\n",
      "         2.0       0.38      0.66      0.48       615\n",
      "\n",
      "    accuracy                           0.59      2700\n",
      "   macro avg       0.50      0.61      0.50      2700\n",
      "weighted avg       0.73      0.59      0.62      2700\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1088  225  628]\n",
      " [  19   88   37]\n",
      " [ 124   84  407]]\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.94      0.90      1941\n",
      "         1.0       0.66      0.51      0.57       144\n",
      "         2.0       0.74      0.53      0.61       615\n",
      "\n",
      "    accuracy                           0.83      2700\n",
      "   macro avg       0.75      0.66      0.70      2700\n",
      "weighted avg       0.82      0.83      0.81      2700\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1833   12   96]\n",
      " [  51   73   20]\n",
      " [ 266   25  324]]\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.79      0.85      1941\n",
      "         1.0       0.43      0.62      0.51       144\n",
      "         2.0       0.53      0.68      0.60       615\n",
      "\n",
      "    accuracy                           0.76      2700\n",
      "   macro avg       0.62      0.70      0.65      2700\n",
      "weighted avg       0.79      0.76      0.77      2700\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1542   70  329]\n",
      " [  17   90   37]\n",
      " [ 147   48  420]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', random_state=50,C= 1)\n",
    "svm.fit(X_train_copies, y_train_copies)\n",
    "predictions_svm = svm.predict(X_test)\n",
    "\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, predictions_svm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_svm))\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=50)\n",
    "rf.fit(X_train_copies, y_train_copies)\n",
    "predictions_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, predictions_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_rf))\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=50)\n",
    "gbc.fit(X_train_copies, y_train_copies)\n",
    "predictions_gbc = gbc.predict(X_test)\n",
    "\n",
    "print(\"Gradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, predictions_gbc))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e911f704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.85      0.85      1941\n",
      "         1.0       0.39      0.42      0.41       144\n",
      "         2.0       0.55      0.53      0.54       615\n",
      "\n",
      "    accuracy                           0.76      2700\n",
      "   macro avg       0.60      0.60      0.60      2700\n",
      "weighted avg       0.76      0.76      0.76      2700\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1659   44  238]\n",
      " [  52   60   32]\n",
      " [ 238   48  329]]\n",
      "k-Nearest Neighbors Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.77      0.80      1941\n",
      "         1.0       0.29      0.31      0.30       144\n",
      "         2.0       0.43      0.52      0.47       615\n",
      "\n",
      "    accuracy                           0.69      2700\n",
      "   macro avg       0.52      0.53      0.52      2700\n",
      "weighted avg       0.71      0.69      0.70      2700\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1490   72  379]\n",
      " [  54   45   45]\n",
      " [ 255   38  322]]\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.42      0.57      1941\n",
      "         1.0       0.20      0.53      0.29       144\n",
      "         2.0       0.30      0.68      0.42       615\n",
      "\n",
      "    accuracy                           0.49      2700\n",
      "   macro avg       0.46      0.54      0.43      2700\n",
      "weighted avg       0.70      0.49      0.52      2700\n",
      "\n",
      "Confusion Matrix:\n",
      "[[818 218 905]\n",
      " [ 14  76  54]\n",
      " [116  82 417]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiuyong/.conda/envs/LiIonMl/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 建立决策树模型\n",
    "dt = DecisionTreeClassifier(random_state=50)\n",
    "dt.fit(X_train_copies, y_train_copies)\n",
    "predictions_dt = dt.predict(X_test)\n",
    "\n",
    "# 打印决策树分类报告和混淆矩阵\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, predictions_dt))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_dt))\n",
    "\n",
    "# 建立k-Nearest Neighbors模型\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_copies, y_train_copies)\n",
    "predictions_knn = knn.predict(X_test)\n",
    "\n",
    "# 打印k-Nearest Neighbors分类报告和混淆矩阵\n",
    "print(\"k-Nearest Neighbors Classification Report:\")\n",
    "print(classification_report(y_test, predictions_knn))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_knn))\n",
    "\n",
    "# 建立Logistic Regression模型\n",
    "lr = LogisticRegression(max_iter=1000, random_state=50)\n",
    "lr.fit(X_train_copies, y_train_copies)\n",
    "predictions_lr = lr.predict(X_test)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, predictions_lr))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9a53077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵:\n",
      "[[1878   10   53]\n",
      " [  68   59   17]\n",
      " [ 332   16  267]]\n",
      "加权平均预测准确率: 0.8162962962962963\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "probs_rf = rf.predict_proba(X_test)\n",
    "probs_dt = dt.predict_proba(X_test)\n",
    "probs_knn = knn.predict_proba(X_test)\n",
    "weighted_avg_probs = 0.4 * probs_rf[:, 0] + 0.3 * probs_dt[:, 0] + 0.3 * probs_knn[:, 0]\n",
    "threshold = 0.4\n",
    "final_predictions = np.where(weighted_avg_probs > threshold,0,predictions_rf)\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, final_predictions)\n",
    "\n",
    "print(\"混淆矩阵:\")\n",
    "print(conf_matrix)\n",
    "print(\"加权平均预测准确率:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27614ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵:\n",
      "[[1876   10   55]\n",
      " [  64   62   18]\n",
      " [ 317   18  280]]\n",
      "加权平均预测准确率: 0.8214814814814815\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "probs_rf = rf.predict_proba(X_test)\n",
    "probs_dt = dt.predict_proba(X_test)\n",
    "probs_knn = knn.predict_proba(X_test)\n",
    "weighted_avg_probs = 0.5 * probs_rf[:, 0] + 0.3 * probs_dt[:, 0] + 0.2 * probs_knn[:, 0]\n",
    "threshold = 0.4\n",
    "final_predictions = np.where(weighted_avg_probs > threshold,0,predictions_rf)\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, final_predictions)\n",
    "\n",
    "print(\"混淆矩阵:\")\n",
    "print(conf_matrix)\n",
    "print(\"加权平均预测准确率:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5cb274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LiIonMl",
   "language": "python",
   "name": "qiuyong"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
