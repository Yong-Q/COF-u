{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c98da656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             ¦Á      LCD      PLD     LFPD    cm3_g  ASA_m2_cm3  ASA_m2_g  \\\n",
      "0     10.467562  5.23722  3.37327  5.23722  1.95599     430.123   219.900   \n",
      "1      8.827184  6.10125  4.48850  6.10125  2.11606    1211.940   572.736   \n",
      "2      7.682237  6.64156  4.20343  6.64156  1.63514     826.484   505.451   \n",
      "3      7.669237  5.13371  3.48538  5.13371  1.96189     431.041   219.707   \n",
      "4      7.052866  5.46070  3.36863  5.46070  1.51914     446.079   293.640   \n",
      "...         ...      ...      ...      ...      ...         ...       ...   \n",
      "7026   0.058403  4.09342  2.99680  4.09342  1.03370       0.000     0.000   \n",
      "7027   0.000000  3.58736  2.63519  3.53963  2.22163       0.000     0.000   \n",
      "7028   0.000000  3.75474  2.61308  3.30325  1.68459       0.000     0.000   \n",
      "7029   0.000000  3.43067  2.87760  3.39852  1.68645       0.000     0.000   \n",
      "7030   0.000000  3.84984  2.72650  3.32788  1.35854       0.000     0.000   \n",
      "\n",
      "      NASA_m2_cm3  NASA_m2_g   AV_VF  AV_cm3_g  NAV_cm3_g  Has_OMS  SOCERE  A  \n",
      "0         0.00000    0.00000  0.3738  0.191105        0.0        1       1  1  \n",
      "1         0.00000    0.00000  0.4754  0.224663        0.0        0       1  1  \n",
      "2         0.00000    0.00000  0.4210  0.257470        0.0        1       1  1  \n",
      "3         0.00000    0.00000  0.3706  0.188900        0.0        1       1  1  \n",
      "4         0.00000    0.00000  0.4404  0.289902        0.0        0       0  1  \n",
      "...           ...        ...     ...       ...        ...      ...     ... ..  \n",
      "7026    279.75700  270.63600  0.5500  0.532068        0.0        1       0  0  \n",
      "7027      7.66668    3.45092  0.3826  0.172216        0.0        1       0  0  \n",
      "7028     78.16320   46.39900  0.4600  0.273064        0.0        1       0  0  \n",
      "7029      3.82399    2.26748  0.4026  0.238726        0.0        1       0  0  \n",
      "7030    148.22100  109.10300  0.4768  0.350964        0.0        0       0  0  \n",
      "\n",
      "[7031 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "data = pd.read_csv('./MOF.csv',encoding='latin1')\n",
    "selected_data = data.iloc[:7032, 15:]\n",
    "print(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adaa8da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.46756154  5.23722     3.37327    ...  1.          1.\n",
      "   1.        ]\n",
      " [ 8.8271839   6.10125     4.4885     ...  0.          1.\n",
      "   1.        ]\n",
      " [ 7.68223746  6.64156     4.20343    ...  1.          1.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 0.          3.75474     2.61308    ...  1.          0.\n",
      "   0.        ]\n",
      " [ 0.          3.43067     2.8776     ...  1.          0.\n",
      "   0.        ]\n",
      " [ 0.          3.84984     2.7265     ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array = selected_data.to_numpy()\n",
    "print (numpy_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51cfc580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.8271839e+00 6.1012500e+00 4.4885000e+00 6.1012500e+00 2.1160600e+00\n",
      " 1.2119400e+03 5.7273600e+02 0.0000000e+00 0.0000000e+00 4.7540000e-01\n",
      " 2.2466300e-01 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "Mm = MinMaxScaler()\n",
    "X=selected_data.iloc[:, :].to_numpy()\n",
    "print(X[1])\n",
    "data = Mm.fit_transform(X)#归一化处理，为后面的监督学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e79532bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "[[10.46756154  5.23722     3.37327    ...  0.191105    0.\n",
      "   1.        ]\n",
      " [ 8.8271839   6.10125     4.4885     ...  0.224663    0.\n",
      "   0.        ]\n",
      " [ 7.68223746  6.64156     4.20343    ...  0.25747     0.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 0.          3.75474     2.61308    ...  0.273064    0.\n",
      "   1.        ]\n",
      " [ 0.          3.43067     2.8776     ...  0.238726    0.\n",
      "   1.        ]\n",
      " [ 0.          3.84984     2.7265     ...  0.350964    0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 提取特征数据和目标变量\n",
    "features = numpy_array[:, :-2]\n",
    "features1 = numpy_array[:, :-2]\n",
    "target = numpy_array[:, -2]\n",
    "print(target)\n",
    "print(features)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=999)\n",
    "#X_train1, X_test1, y_train1, y_test1 = train_test_split(features1, target, test_size=0.3, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d592cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 原始的训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=999)\n",
    "\n",
    "# 找到标签为1的索引\n",
    "index_of_ones = np.where(y_train == 1)[0]\n",
    "\n",
    "# 复制标签为1的数据多份\n",
    "num_copies_1 = 50  # 假设需要复制20份\n",
    "index_to_copy_1 = np.random.choice(index_of_ones, size=len(index_of_ones)*num_copies_1, replace=True)\n",
    "\n",
    "# 将标签为1的数据复制多份并添加到训练集中\n",
    "X_train_copies = np.concatenate([X_train, X_train[index_to_copy_1]])\n",
    "y_train_copies = np.concatenate([y_train, y_train[index_to_copy_1]])\n",
    "\n",
    "# 找到标签为2的索引\n",
    "index_of_twos = np.where(y_train == 2)[0]\n",
    "\n",
    "# 复制标签为2的数据多份\n",
    "num_copies_2 = 10  # 假设需要复制10份\n",
    "index_to_copy_2 = np.random.choice(index_of_twos, size=len(index_of_twos)*num_copies_2, replace=True)\n",
    "\n",
    "# 将标签为2的数据复制多份并添加到训练集中\n",
    "X_train_copies = np.concatenate([X_train_copies, X_train[index_to_copy_2]])\n",
    "y_train_copies = np.concatenate([y_train_copies, y_train[index_to_copy_2]])\n",
    "\n",
    "index_of_0s = np.where(y_train == 0)[0]\n",
    "\n",
    "# 复制标签为2的数据多份\n",
    "num_copies_0 = 2  # 假设需要复制10份\n",
    "index_to_copy_0 = np.random.choice(index_of_0s, size=len(index_of_0s)*num_copies_0, replace=True)\n",
    "\n",
    "# 将标签为2的数据复制多份并添加到训练集中\n",
    "X_train_copies = np.concatenate([X_train_copies, X_train[index_to_copy_0]])\n",
    "y_train_copies = np.concatenate([y_train_copies, y_train[index_to_copy_0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1223ff9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.75      0.83      1578\n",
      "         1.0       0.34      0.76      0.47       105\n",
      "         2.0       0.44      0.64      0.52       427\n",
      "\n",
      "    accuracy                           0.73      2110\n",
      "   macro avg       0.57      0.72      0.61      2110\n",
      "weighted avg       0.81      0.73      0.75      2110\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1183   74  321]\n",
      " [   4   80   21]\n",
      " [  73   82  272]]\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.94      0.92      1578\n",
      "         1.0       0.74      0.68      0.71       105\n",
      "         2.0       0.68      0.58      0.62       427\n",
      "\n",
      "    accuracy                           0.85      2110\n",
      "   macro avg       0.77      0.73      0.75      2110\n",
      "weighted avg       0.84      0.85      0.85      2110\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1480    9   89]\n",
      " [   6   71   28]\n",
      " [ 164   16  247]]\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.83      0.88      1578\n",
      "         1.0       0.52      0.80      0.63       105\n",
      "         2.0       0.53      0.69      0.59       427\n",
      "\n",
      "    accuracy                           0.80      2110\n",
      "   macro avg       0.66      0.77      0.70      2110\n",
      "weighted avg       0.83      0.80      0.81      2110\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1303   29  246]\n",
      " [   2   84   19]\n",
      " [  84   50  293]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 建立SVM模型\n",
    "svm = SVC(kernel='linear', random_state=50,C= 1)\n",
    "svm.fit(X_train_copies, y_train_copies)\n",
    "predictions_svm = svm.predict(X_test)\n",
    "\n",
    "# 打印SVM分类报告和混淆矩阵\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, predictions_svm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_svm))\n",
    "\n",
    "# 建立随机森林模型\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=50)\n",
    "rf.fit(X_train_copies, y_train_copies)\n",
    "predictions_rf = rf.predict(X_test)\n",
    "\n",
    "# 打印随机森林分类报告和混淆矩阵\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, predictions_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_rf))\n",
    "\n",
    "# 建立梯度提升树模型\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=50)\n",
    "gbc.fit(X_train_copies, y_train_copies)\n",
    "predictions_gbc = gbc.predict(X_test)\n",
    "\n",
    "# 打印梯度提升树分类报告和混淆矩阵\n",
    "print(\"Gradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, predictions_gbc))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_gbc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b80162c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.88      0.87      1578\n",
      "         1.0       0.61      0.60      0.61       105\n",
      "         2.0       0.52      0.51      0.51       427\n",
      "\n",
      "    accuracy                           0.79      2110\n",
      "   macro avg       0.67      0.66      0.66      2110\n",
      "weighted avg       0.79      0.79      0.79      2110\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1385   16  177]\n",
      " [  16   63   26]\n",
      " [ 187   24  216]]\n",
      "k-Nearest Neighbors Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.76      0.79      1578\n",
      "         1.0       0.22      0.30      0.25       105\n",
      "         2.0       0.38      0.46      0.42       427\n",
      "\n",
      "    accuracy                           0.68      2110\n",
      "   macro avg       0.48      0.51      0.49      2110\n",
      "weighted avg       0.71      0.68      0.69      2110\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1196   85  297]\n",
      " [  45   32   28]\n",
      " [ 200   30  197]]\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.71      0.81      1578\n",
      "         1.0       0.27      0.84      0.40       105\n",
      "         2.0       0.39      0.51      0.44       427\n",
      "\n",
      "    accuracy                           0.68      2110\n",
      "   macro avg       0.53      0.69      0.55      2110\n",
      "weighted avg       0.79      0.68      0.71      2110\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1126  119  333]\n",
      " [   4   88   13]\n",
      " [  83  125  219]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiuyong/.conda/envs/LiIonMl/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 建立决策树模型\n",
    "dt = DecisionTreeClassifier(random_state=50)\n",
    "dt.fit(X_train_copies, y_train_copies)\n",
    "predictions_dt = dt.predict(X_test)\n",
    "\n",
    "# 打印决策树分类报告和混淆矩阵\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, predictions_dt))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_dt))\n",
    "\n",
    "# 建立k-Nearest Neighbors模型\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_copies, y_train_copies)\n",
    "predictions_knn = knn.predict(X_test)\n",
    "\n",
    "# 打印k-Nearest Neighbors分类报告和混淆矩阵\n",
    "print(\"k-Nearest Neighbors Classification Report:\")\n",
    "print(classification_report(y_test, predictions_knn))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_knn))\n",
    "\n",
    "# 建立Logistic Regression模型\n",
    "lr = LogisticRegression(max_iter=1000, random_state=50)\n",
    "lr.fit(X_train_copies, y_train_copies)\n",
    "predictions_lr = lr.predict(X_test)\n",
    "\n",
    "# 打印Logistic Regression分类报告和混淆矩阵\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, predictions_lr))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b4ab926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵:\n",
      "[[1529    7   42]\n",
      " [  17   65   23]\n",
      " [ 246   13  168]]\n",
      "加权平均预测准确率: 0.8350710900473933\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 假设predictions_rf、predictions_dt、predictions_knn是随机森林、决策树和k-Nearest Neighbors的预测结果\n",
    "# 分别对应模型的类别概率\n",
    "probs_rf = rf.predict_proba(X_test)\n",
    "probs_dt = dt.predict_proba(X_test)\n",
    "probs_knn = knn.predict_proba(X_test)\n",
    "\n",
    "# 对预测类型1的加权平均\n",
    "weighted_avg_probs = 0.4 * probs_rf[:, 0] + 0.3 * probs_dt[:, 0] + 0.3 * probs_knn[:, 0]\n",
    "#print(probs_rf[:, 0])\n",
    "# 设置阈值，当加权平均概率超过阈值时，认定为类型1\n",
    "threshold = 0.4\n",
    "\n",
    "# 根据阈值判断最终的预测类型\n",
    "final_predictions = np.where(weighted_avg_probs > threshold,0,predictions_rf)\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, final_predictions)\n",
    "\n",
    "print(\"混淆矩阵:\")\n",
    "print(conf_matrix)\n",
    "print(\"加权平均预测准确率:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f003bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 原始的训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=999)\n",
    "\n",
    "# 找到标签为1的索引\n",
    "index_of_ones = np.where(y_train == 1)[0]\n",
    "\n",
    "# 复制标签为1的数据多份\n",
    "num_copies_1 = 30  # 假设需要复制20份\n",
    "index_to_copy_1 = np.random.choice(index_of_ones, size=len(index_of_ones)*num_copies_1, replace=True)\n",
    "\n",
    "# 将标签为1的数据复制多份并添加到训练集中\n",
    "X_train_copies = np.concatenate([X_train, X_train[index_to_copy_1]])\n",
    "y_train_copies = np.concatenate([y_train, y_train[index_to_copy_1]])\n",
    "\n",
    "# 找到标签为2的索引\n",
    "index_of_twos = np.where(y_train == 2)[0]\n",
    "\n",
    "# 复制标签为2的数据多份\n",
    "num_copies_2 = 10  # 假设需要复制10份\n",
    "index_to_copy_2 = np.random.choice(index_of_twos, size=len(index_of_twos)*num_copies_2, replace=True)\n",
    "\n",
    "# 将标签为2的数据复制多份并添加到训练集中\n",
    "X_train_copies = np.concatenate([X_train_copies, X_train[index_to_copy_2]])\n",
    "y_train_copies = np.concatenate([y_train_copies, y_train[index_to_copy_2]])\n",
    "\n",
    "index_of_0s = np.where(y_train == 0)[0]\n",
    "\n",
    "# 复制标签为2的数据多份\n",
    "num_copies_0 = 2  # 假设需要复制10份\n",
    "index_to_copy_0 = np.random.choice(index_of_0s, size=len(index_of_0s)*num_copies_0, replace=True)\n",
    "\n",
    "# 将标签为2的数据复制多份并添加到训练集中\n",
    "X_train_copies = np.concatenate([X_train_copies, X_train[index_to_copy_0]])\n",
    "y_train_copies = np.concatenate([y_train_copies, y_train[index_to_copy_0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a00f799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.74      0.83      1578\n",
      "         1.0       0.38      0.70      0.49       105\n",
      "         2.0       0.44      0.69      0.54       427\n",
      "\n",
      "    accuracy                           0.73      2110\n",
      "   macro avg       0.59      0.71      0.62      2110\n",
      "weighted avg       0.81      0.73      0.75      2110\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1171   64  343]\n",
      " [   4   73   28]\n",
      " [  75   56  296]]\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.94      0.92      1578\n",
      "         1.0       0.72      0.69      0.70       105\n",
      "         2.0       0.69      0.58      0.63       427\n",
      "\n",
      "    accuracy                           0.85      2110\n",
      "   macro avg       0.77      0.73      0.75      2110\n",
      "weighted avg       0.85      0.85      0.85      2110\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1485   10   83]\n",
      " [   6   72   27]\n",
      " [ 163   18  246]]\n",
      "Gradient Boosting Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.83      0.88      1578\n",
      "         1.0       0.56      0.79      0.65       105\n",
      "         2.0       0.54      0.71      0.62       427\n",
      "\n",
      "    accuracy                           0.81      2110\n",
      "   macro avg       0.68      0.78      0.72      2110\n",
      "weighted avg       0.84      0.81      0.82      2110\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1313   27  238]\n",
      " [   2   83   20]\n",
      " [  83   39  305]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 建立SVM模型\n",
    "svm = SVC(kernel='linear', random_state=50,C= 1)\n",
    "svm.fit(X_train_copies, y_train_copies)\n",
    "predictions_svm = svm.predict(X_test)\n",
    "\n",
    "# 打印SVM分类报告和混淆矩阵\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, predictions_svm))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_svm))\n",
    "\n",
    "# 建立随机森林模型\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=50)\n",
    "rf.fit(X_train_copies, y_train_copies)\n",
    "predictions_rf = rf.predict(X_test)\n",
    "\n",
    "# 打印随机森林分类报告和混淆矩阵\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, predictions_rf))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_rf))\n",
    "\n",
    "# 建立梯度提升树模型\n",
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=4, random_state=50)\n",
    "gbc.fit(X_train_copies, y_train_copies)\n",
    "predictions_gbc = gbc.predict(X_test)\n",
    "\n",
    "# 打印梯度提升树分类报告和混淆矩阵\n",
    "print(\"Gradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, predictions_gbc))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e911f704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.89      0.89      1578\n",
      "         1.0       0.62      0.67      0.64       105\n",
      "         2.0       0.56      0.55      0.56       427\n",
      "\n",
      "    accuracy                           0.81      2110\n",
      "   macro avg       0.69      0.70      0.70      2110\n",
      "weighted avg       0.81      0.81      0.81      2110\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1400   22  156]\n",
      " [   8   70   27]\n",
      " [ 170   21  236]]\n",
      "k-Nearest Neighbors Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.75      0.79      1578\n",
      "         1.0       0.22      0.31      0.26       105\n",
      "         2.0       0.37      0.46      0.41       427\n",
      "\n",
      "    accuracy                           0.67      2110\n",
      "   macro avg       0.47      0.51      0.49      2110\n",
      "weighted avg       0.71      0.67      0.69      2110\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1185   85  308]\n",
      " [  40   33   32]\n",
      " [ 201   30  196]]\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.73      0.82      1578\n",
      "         1.0       0.31      0.76      0.44       105\n",
      "         2.0       0.43      0.63      0.51       427\n",
      "\n",
      "    accuracy                           0.71      2110\n",
      "   macro avg       0.56      0.71      0.59      2110\n",
      "weighted avg       0.80      0.71      0.74      2110\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1153   95  330]\n",
      " [   4   80   21]\n",
      " [  78   81  268]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qiuyong/.conda/envs/LiIonMl/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 建立决策树模型\n",
    "dt = DecisionTreeClassifier(random_state=50)\n",
    "dt.fit(X_train_copies, y_train_copies)\n",
    "predictions_dt = dt.predict(X_test)\n",
    "\n",
    "# 打印决策树分类报告和混淆矩阵\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, predictions_dt))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_dt))\n",
    "\n",
    "# 建立k-Nearest Neighbors模型\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_copies, y_train_copies)\n",
    "predictions_knn = knn.predict(X_test)\n",
    "\n",
    "# 打印k-Nearest Neighbors分类报告和混淆矩阵\n",
    "print(\"k-Nearest Neighbors Classification Report:\")\n",
    "print(classification_report(y_test, predictions_knn))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_knn))\n",
    "\n",
    "# 建立Logistic Regression模型\n",
    "lr = LogisticRegression(max_iter=1000, random_state=50)\n",
    "lr.fit(X_train_copies, y_train_copies)\n",
    "predictions_lr = lr.predict(X_test)\n",
    "\n",
    "# 打印Logistic Regression分类报告和混淆矩阵\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, predictions_lr))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9a53077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵:\n",
      "[[1525    8   45]\n",
      " [  13   70   22]\n",
      " [ 228   15  184]]\n",
      "加权平均预测准确率: 0.843127962085308\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 假设predictions_rf、predictions_dt、predictions_knn是随机森林、决策树和k-Nearest Neighbors的预测结果\n",
    "# 分别对应模型的类别概率\n",
    "probs_rf = rf.predict_proba(X_test)\n",
    "probs_dt = dt.predict_proba(X_test)\n",
    "probs_knn = knn.predict_proba(X_test)\n",
    "\n",
    "# 对预测类型1的加权平均\n",
    "weighted_avg_probs = 0.4 * probs_rf[:, 0] + 0.3 * probs_dt[:, 0] + 0.3 * probs_knn[:, 0]\n",
    "#print(probs_rf[:, 0])\n",
    "# 设置阈值，当加权平均概率超过阈值时，认定为类型1\n",
    "threshold = 0.4\n",
    "\n",
    "# 根据阈值判断最终的预测类型\n",
    "final_predictions = np.where(weighted_avg_probs > threshold,0,predictions_rf)\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, final_predictions)\n",
    "\n",
    "print(\"混淆矩阵:\")\n",
    "print(conf_matrix)\n",
    "print(\"加权平均预测准确率:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27614ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "混淆矩阵:\n",
      "[[1513    9   56]\n",
      " [   8   72   25]\n",
      " [ 215   15  197]]\n",
      "加权平均预测准确率: 0.8445497630331753\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "# 假设predictions_rf、predictions_dt、predictions_knn是随机森林、决策树和k-Nearest Neighbors的预测结果\n",
    "# 分别对应模型的类别概率\n",
    "probs_rf = rf.predict_proba(X_test)\n",
    "probs_dt = dt.predict_proba(X_test)\n",
    "probs_knn = knn.predict_proba(X_test)\n",
    "\n",
    "# 对预测类型1的加权平均\n",
    "weighted_avg_probs = 0.5 * probs_rf[:, 0] + 0.3 * probs_dt[:, 0] + 0.2 * probs_knn[:, 0]\n",
    "#print(probs_rf[:, 0])\n",
    "# 设置阈值，当加权平均概率超过阈值时，认定为类型1\n",
    "threshold = 0.4\n",
    "\n",
    "# 根据阈值判断最终的预测类型\n",
    "final_predictions = np.where(weighted_avg_probs > threshold,0,predictions_rf)\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_test, final_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, final_predictions)\n",
    "\n",
    "print(\"混淆矩阵:\")\n",
    "print(conf_matrix)\n",
    "print(\"加权平均预测准确率:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5cb274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LiIonMl",
   "language": "python",
   "name": "qiuyong"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
